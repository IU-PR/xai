<!doctype html><html lang=en-us dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Implementation of Grad-CAM++ and Prediction Explanation for a ResNet Model in Object Detection and Classification # Authors: Elena Tesmeeva, Nazgul Salikhova
Explainable AI (XAI): An Overview # As machine learning models grow more complex, it becomes harder to understand why they make certain predictions. This black-box nature isn’t always a problem in low-risk settings, but in critical fields like healthcare or finance, lack of transparency can be risky or even harmful."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://localhost:1313/docs/groups/grad-cam++/"><meta property="og:site_name" content="XAI"><meta property="og:title" content="Grad-CAM++"><meta property="og:description" content="Implementation of Grad-CAM++ and Prediction Explanation for a ResNet Model in Object Detection and Classification # Authors: Elena Tesmeeva, Nazgul Salikhova
Explainable AI (XAI): An Overview # As machine learning models grow more complex, it becomes harder to understand why they make certain predictions. This black-box nature isn’t always a problem in low-risk settings, but in critical fields like healthcare or finance, lack of transparency can be risky or even harmful."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Grad-CAM++ | XAI</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.e832d4e94212199857473bcf13a450d089c3fcd54ccadedcfac84ed0feff83fb.css integrity="sha256-6DLU6UISGZhXRzvPE6RQ0InD/NVMyt7c+shO0P7/g/s=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/mathtex-script-type.min.js integrity=sha384-jiBVvJ8NGGj5n7kJaiWwWp9AjC+Yh8rhZY3GtAX8yU28azcLgoRo4oukO87g7zDT crossorigin=anonymous></script><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.fa9a5612c6d891d8ff3a763f9eb1c2916a388026163bc6bf2e7cd1c2ec1740aa.js integrity="sha256-+ppWEsbYkdj/OnY/nrHCkWo4gCYWO8a/LnzRwuwXQKo=" crossorigin=anonymous></script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/YELLOW_BAR.png alt=Logo><span><b>XAI</b></span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/groups/cam_and_secam/>CAM and SeCAM</a></li><li><a href=/docs/groups/diffusion-lens-interpreting-text-encoders-in-text-to-image-pipelines-tuned-using-dreambooth/>Diffusion Lens: Interpreting Text Encoders in Text-to-Image pipelines</a></li><li><a href=/docs/groups/dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne/>Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE</a></li><li><a href=/docs/groups/example/>Example</a></li><li><a href=/docs/groups/grad-cam++/ class=active>Grad-CAM++</a></li><li><a href=/docs/groups/ai-playing-geoguessr-explained/>Ai Playing Geo Guessr Explained</a></li><li><a href=/docs/groups/contrastive-grad-cam-consistency/>Contrastive Grad Cam Consistency</a></li><li><a href=/docs/groups/dndfs_shap/>Dndfs Shap</a></li><li><a href=/docs/groups/gradcam/>Grad Cam</a></li><li><a href=/docs/groups/integrated-gradients/>Integrated Gradients</a></li><li><a href=/docs/groups/kernel-shap/>Kernel Shap</a></li><li><a href=/docs/groups/rag/>Rag</a></li><li><a href=/docs/groups/shap_darya_and_viktoria/>Shap Darya and Viktoria</a></li><li><a href=/docs/groups/sverl_tac_toe/>Sverl Tac Toe</a></li><li><a href=/docs/groups/torchprism/>Torch Prism</a></li><li><a href=/docs/groups/xai_for_transformers/>Xai for Transformers</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Grad-CAM++</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#implementation-of-grad-cam-and-prediction-explanation-for-a-resnet-model-in-object-detection-and-classification>Implementation of Grad-CAM++ and Prediction Explanation for a ResNet Model in Object Detection and Classification</a><ul><li><a href=#explainable-ai-xai-an-overview>Explainable AI (XAI): An Overview</a></li><li><a href=#overview-of-grad-cam>Overview of Grad-CAM++</a><ul><li></li></ul></li><li><a href=#comparison-grad-cam-vs-grad-cam-vs-cam>Comparison: Grad-CAM vs Grad-CAM++ vs CAM</a></li><li><a href=#overview-of-the-chosen-visual-model>Overview of the Chosen Visual Model</a></li><li><a href=#mini-tutorial-how-to-apply-grad-cam-to-your-model>Mini Tutorial: How to Apply Grad-CAM++ to Your Model</a></li><li><a href=#experiments-of-grad-cam-on-resnet-50>Experiments of Grad-CAM++ on ResNet-50</a></li><li><a href=#results>Results</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#google-colab-link>Google Colab Link</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=implementation-of-grad-cam-and-prediction-explanation-for-a-resnet-model-in-object-detection-and-classification>Implementation of Grad-CAM++ and Prediction Explanation for a ResNet Model in Object Detection and Classification
<a class=anchor href=#implementation-of-grad-cam-and-prediction-explanation-for-a-resnet-model-in-object-detection-and-classification>#</a></h1><p><strong>Authors: Elena Tesmeeva, Nazgul Salikhova</strong></p><h2 id=explainable-ai-xai-an-overview>Explainable AI (XAI): An Overview
<a class=anchor href=#explainable-ai-xai-an-overview>#</a></h2><p>As machine learning models grow more complex, it becomes harder to understand <em>why</em> they make certain predictions. This black-box nature isn’t always a problem in low-risk settings, but in critical fields like healthcare or finance, lack of transparency can be risky or even harmful.</p><p><strong>Explainable AI (XAI)</strong> is a set of techniques designed to shed light on a model’s decision-making process. The idea is to go beyond just high accuracy—to also understand <em>what</em> parts of the input the model focused on, <em>how</em> it reached a conclusion, and <em>whether</em> the reasoning seems reasonable or flawed.</p><p>XAI methods help build trust in models, allow for better debugging, and support regulatory requirements (like GDPR). Some popular tools and methods in this area include:</p><ul><li><strong>Saliency Maps</strong> – Highlight which pixels or input features contributed most to a prediction.</li><li><strong>LIME</strong> (Local Interpretable Model-agnostic Explanations) – Explains individual predictions by approximating the model locally with an interpretable one.</li><li><strong>SHAP</strong> (SHapley Additive exPlanations) – Assigns importance scores to features based on cooperative game theory.</li><li><strong>Grad-CAM</strong> and <strong>Grad-CAM++</strong> – Visualize which regions of an image a CNN focused on when making a classification.</li></ul><p>In essence, XAI helps open the <em>black box</em> of deep learning and makes models not just powerful, but also understandable and trustworthy.</p><hr><h2 id=overview-of-grad-cam>Overview of Grad-CAM++
<a class=anchor href=#overview-of-grad-cam>#</a></h2><p>Grad-CAM++ (Gradient-weighted Class Activation Mapping++) is an advanced version of Grad-CAM, developed to provide improved visual explanations for decisions made by convolutional neural networks (CNNs). Grad-CAM works by utilizing the gradients of a target concept flowing into the final convolutional layer to produce a hard localization map highlighting important regions in the image.</p><p>Grad-CAM++, however, refines this approach by using second and third-order derivatives of the output with respect to the convolutional feature maps. This makes Grad-CAM++ better suited for:</p><ul><li>Images containing multiple object instances</li><li>Improving localization of class-specific regions</li><li>Generating finer, more precise heatmaps</li></ul><h4 id=key-equation>Key Equation:
<a class=anchor href=#key-equation>#</a></h4><p>The key equation for Grad-CAM++ is the following:</p><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js async></script><div align=center>$$
\text{Grad-CAM}^{++}(\mathbf{A}, \mathbf{C}) = \sum_{i} \sum_{j} \alpha_{ij} \cdot \text{ReLU}\left(\sum_{k} \frac{\partial y_{C}}{\partial A_{ijk}} \right) \cdot A_{ijk}
$$</div><p><strong>Where:</strong></p><ul><li><strong>A</strong> is the feature map from the last convolutional layer.</li><li><strong>C</strong> is the target class.</li><li><strong>α<sub>ij</sub></strong> represents the importance of each activation after applying the Taylor expansion.</li><li><strong>A<sub>ijk</sub></strong> is the activation value for each location in the feature map.</li><li>The gradients <strong>∂y<sub>C</sub>/∂A<sub>ijk</sub></strong> are used to compute the weight of each feature map for class C.</li></ul><p>The main idea behind Grad-CAM++ is to assign better importance weights to the feature maps in the last convolutional layer, leading to more accurate explanations without retraining or modifying the model.</p><hr><h2 id=comparison-grad-cam-vs-grad-cam-vs-cam>Comparison: Grad-CAM vs Grad-CAM++ vs CAM
<a class=anchor href=#comparison-grad-cam-vs-grad-cam-vs-cam>#</a></h2><table><thead><tr><th>Feature</th><th>Grad-CAM</th><th>Grad-CAM++</th><th>CAM</th></tr></thead><tbody><tr><td>Uses gradients</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>Higher-order derivatives</td><td>No</td><td>Yes</td><td>No</td></tr><tr><td>Forward pass only</td><td>No</td><td>No</td><td>Yes</td></tr><tr><td>Localization accuracy</td><td>Medium</td><td>High</td><td>High</td></tr><tr><td>Handles multiple objects</td><td>Poor</td><td>Good</td><td>Good</td></tr><tr><td>Computational efficiency</td><td>High</td><td>Moderate</td><td>Low</td></tr></tbody></table><p>Grad-CAM++ builds on the strengths of Grad-CAM by using more complex derivatives to better weigh the importance of each activation. While Score-CAM avoids gradients altogether and uses activation maps weighted by class scores, it is more computationally intensive due to multiple forward passes. Grad-CAM++ thus strikes a balance between interpretability and efficiency.</p><p><img src=/Grad-CAM++/comp.png alt=An-overview-of-all-the-three-methods-CAM-Grad-CAM-GradCAM-with-their-respective></p><hr><h2 id=overview-of-the-chosen-visual-model>Overview of the Chosen Visual Model
<a class=anchor href=#overview-of-the-chosen-visual-model>#</a></h2><p>For this project, we used <strong>ResNet-50</strong>, a deep convolutional neural network developed by Microsoft Research. The architecture is well-known for its use of <strong>residual blocks</strong>, which make it easier to train deep networks by enabling shortcut connections that help gradients flow more effectively during backpropagation.</p><p>ResNet-50 is particularly effective for image classification tasks due to its depth and ability to capture complex features. To interpret the model’s predictions, we applied <strong>Grad-CAM++</strong>, a powerful explainability technique that highlights the important regions in the input image that contribute most to the model’s decision.</p><p>For generating the class activation maps, we used the <strong>final block of layer4[-1] (Stage 4)</strong> in the ResNet-50 architecture. This layer captures high-level semantic information, making it suitable for visualizing the reasoning behind the model&rsquo;s predictions.</p><p><img src=/Grad-CAM++/resnet50.jpg alt="ResNet-50 Architecture"></p><p>On the training set, we achieved an accuracy of 95.63%, while the test set accuracy was 78.5% on 10 epochs.</p><p>The classification results on the Skin Cancer MNIST: HAM10000 dataset using ResNet-50 demonstrate solid overall performance with an accuracy of 78.5%, but also highlight challenges related to class imbalance. The model performs exceptionally well on the dominant class (label 4 – likely melanocytic nevi) with an F1-score of 0.88, while underrepresented classes (e.g., labels 0, 3, and 5) show noticeably lower precision and recall. This imbalance leads to a macro average F1-score of 0.63, indicating that while the model performs well on average when weighted by class size, its ability to generalize across all classes is limited. Improving minority class performance may require techniques like data augmentation, oversampling, or fine-tuning class weights.</p><hr><h2 id=mini-tutorial-how-to-apply-grad-cam-to-your-model>Mini Tutorial: How to Apply Grad-CAM++ to Your Model
<a class=anchor href=#mini-tutorial-how-to-apply-grad-cam-to-your-model>#</a></h2><p>Here is a simplified algorithm for applying Grad-CAM++ to any CNN-based model in PyTorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> models, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> PIL <span style=color:#f92672>import</span> Image
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> gradcam <span style=color:#f92672>import</span> GradCAMPlusPlus  <span style=color:#75715e># Check our implementation in the Colab notebook</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Step 1: Load a pretrained model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>resnet50(pretrained<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Step 2: Set up Grad-CAM++</span>
</span></span><span style=display:flex><span>gradcam <span style=color:#f92672>=</span> GradCAMPlusPlus(model, target_layer<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;layer4&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Step 3: Load and preprocess the image</span>
</span></span><span style=display:flex><span>image <span style=color:#f92672>=</span> Image<span style=color:#f92672>.</span>open(<span style=color:#e6db74>&#34;example.jpg&#34;</span>)
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize((<span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>)),
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ToTensor(),
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>input_tensor <span style=color:#f92672>=</span> transform(image)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Step 4: Generate the Grad-CAM++ heatmap</span>
</span></span><span style=display:flex><span>heatmap <span style=color:#f92672>=</span> gradcam(input_tensor, class_idx<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)  <span style=color:#75715e># Automatically uses the predicted class</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Step 5: Overlay heatmap on original image</span>
</span></span><span style=display:flex><span>gradcam<span style=color:#f92672>.</span>visualize(image, heatmap)
</span></span></code></pre></div><hr><h2 id=experiments-of-grad-cam-on-resnet-50>Experiments of Grad-CAM++ on ResNet-50
<a class=anchor href=#experiments-of-grad-cam-on-resnet-50>#</a></h2><p>In our project, we fine-tuned ResNet-50 using the HAM10000 dataset for skin lesion classification. We then applied Grad-CAM++ to generate class activation heatmaps to understand which parts of the image influenced the model&rsquo;s decision.</p><div style=display:flex;align-items:center;justify-content:space-between><div style=flex:1;padding-right:20px><p>The dataset used in this project is the <strong>Skin Cancer MNIST: HAM10000</strong>, sourced from
<a href=https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000/data>Kaggle</a>. It comprises <strong>10,015 dermatoscopic images</strong> of pigmented skin lesions collected from multiple sources and populations, with a variety of acquisition modalities. The dataset serves as an excellent resource for training and evaluating machine learning models for skin lesion classification.</p></div><div style=flex-shrink:0><img src=https://s4.gifyu.com/images/bpCkE.gif alt="GradCAM++ results GIF" style=max-height:300px></div></div><p>The results were promising: the Grad-CAM++ visualizations often highlighted the core lesion areas, giving us confidence that the model focuses on medically relevant regions. This is particularly important in healthcare settings, where model transparency and trust are crucial.</p><p>The notebook includes examples where the original image, the activation heatmap, and the overlaid visualization are displayed side-by-side for clear comparison.</p><p>In the following GIF it can be noteced that the model predicts the label of the image and the presence or absence of cancer.
There is also important information about visualization using hitmans. For a simplified understanding, we have made the opposite display for images with and without a certain cancer. In the cancer images, the model&rsquo;s main focus and the mole itself will be in red. The images are cancer-free. the part that signals this - the birthmark - will be blue, so that the difference is immediately visually clear the difference between cancer and bening labelled images.</p><div style=flex-shrink:0><img src=https://s4.gifyu.com/images/bpCQL.gif alt="GradCAM++ results GIF" style=max-height:300px></div><hr><h2 id=results>Results
<a class=anchor href=#results>#</a></h2><p>The results show that all three methods—<strong>Grad-CAM</strong>, <strong>Grad-CAM++</strong>, and <strong>CAM</strong>—are effective at highlighting important regions in the image that the model uses for prediction. However, each has its own strengths:</p><ul><li><strong>Grad-CAM++</strong> creates the most detailed and precise heatmaps. It’s especially good at highlighting small or fragmented areas, which is helpful when fine detail matters.</li><li><strong>Grad-CAM</strong> is slightly more general, producing smoother heatmaps, but still gives reliable and consistent results. It’s a strong all-around option.</li><li><strong>CAM</strong> doesn’t use gradients, so its heatmaps are less focused. Still, it’s useful as a second check because it confirms where the model is paying attention without relying on backpropagation.</li></ul><p>An important insight from our experiment is that when all three methods agree on the key regions, we can be much more confident in the model’s prediction. This kind of cross-validation is especially useful in medical imaging, where being wrong can have serious consequences.</p><p><img src=https://hackmd.io/_uploads/BkDWlkrJge.png alt=Unknown-2>
<img src=https://hackmd.io/_uploads/Sk0Wl1rJxe.png alt=Unknown-3>
<img src=https://hackmd.io/_uploads/SkZzgJH1ll.png alt=Unknown-4></p><hr><h2 id=conclusion>Conclusion
<a class=anchor href=#conclusion>#</a></h2><p>This project underscores the importance of explainability in deep learning, particularly within the context of medical imaging. We demonstrated how Grad-CAM++ enhances the interpretability of a ResNet-50 model trained on the HAM10000 skin cancer dataset. Compared to traditional Grad-CAM, Grad-CAM++ produced sharper and more accurate visual explanations while being computationally more efficient than CAM.</p><p>Grad-CAM++ emerges as a practical tool for researchers and practitioners seeking model transparency without significantly compromising performance. It contributes to the development of responsible AI and helps bridge the gap between black-box predictions and human interpretability.</p><p>We believe that Grad-CAM++ can serve as a reliable second opinion in clinical decision-support systems — especially valuable when AI-generated insights align with human expertise.</p><hr><h2 id=google-colab-link>Google Colab Link
<a class=anchor href=#google-colab-link>#</a></h2><p>To check our implementation:
<a href="https://colab.research.google.com/drive/1NlSx-AVHM8iu62ezZddtWghuCafMkXT1?usp=sharing">Google Colab</a></p><hr><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ol><li><p><strong>Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks</strong><br>Aditya Chattopadhyay et al.<br><a href=https://arxiv.org/abs/1710.11063>arXiv:1710.11063</a><br><em>Original paper introducing Grad-CAM++</em></p></li><li><p><strong>HAM10000 Dataset</strong><br>Kaggle:
<a href=https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000/data>Skin Cancer MNIST: HAM10000</a><br><em>Dermatoscopic images of pigmented lesions for skin cancer classification</em></p></li><li><p><strong>Grad-CAM: Visual Explanations from Deep Networks</strong><br>Ramprasaath R. Selvaraju et al.<br><a href=https://arxiv.org/pdf/1610.02391>arXiv:1610.02391</a><br><em>Foundational work on gradient-based class activation mapping</em></p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/IU-PR/Capstone_project/tree/master//content/docs/Groups/Grad-CAM++.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#implementation-of-grad-cam-and-prediction-explanation-for-a-resnet-model-in-object-detection-and-classification>Implementation of Grad-CAM++ and Prediction Explanation for a ResNet Model in Object Detection and Classification</a><ul><li><a href=#explainable-ai-xai-an-overview>Explainable AI (XAI): An Overview</a></li><li><a href=#overview-of-grad-cam>Overview of Grad-CAM++</a><ul><li></li></ul></li><li><a href=#comparison-grad-cam-vs-grad-cam-vs-cam>Comparison: Grad-CAM vs Grad-CAM++ vs CAM</a></li><li><a href=#overview-of-the-chosen-visual-model>Overview of the Chosen Visual Model</a></li><li><a href=#mini-tutorial-how-to-apply-grad-cam-to-your-model>Mini Tutorial: How to Apply Grad-CAM++ to Your Model</a></li><li><a href=#experiments-of-grad-cam-on-resnet-50>Experiments of Grad-CAM++ on ResNet-50</a></li><li><a href=#results>Results</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#google-colab-link>Google Colab Link</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></div></aside></main></body></html>